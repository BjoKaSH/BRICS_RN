<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>BRICS_RN_Robust_Navigation_Library(BRICS_RN): Introduction to the used algorithm taxonomy</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.7.3 -->
<div id="top">
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">BRICS_RN_Robust_Navigation_Library(BRICS_RN)&#160;<span id="projectnumber">0.01</span></div>
  </td>
 </tr>
 </tbody>
</table>
</div>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<h1>Introduction to the used algorithm taxonomy </h1>  </div>
</div>
<div class="contents">
<div class="textblock"><h2><a class="anchor" id="taxonomy"></a>
Algorithm taxonomy</h2>
<p>The 3D perception and modeling domain can be classified into several subareas:</p>
<ul>
<li><a class="el" href="introduction.html#depth_perception_def">Depth perception</a></li>
<li><a class="el" href="introduction.html#filtering_def">Filtering</a></li>
<li><a class="el" href="introduction.html#feature_extraction_def">Feature extraction</a></li>
<li><a class="el" href="introduction.html#registration_def">Registration</a></li>
<li><a class="el" href="introduction.html#segmentation_def">Segmentation</a></li>
<li><a class="el" href="introduction.html#classification_def">Classification</a></li>
<li><a class="el" href="introduction.html#mesh_generation_def">Mesh generation</a></li>
<li><a class="el" href="introduction.html#visualization_def">Visualization</a></li>
</ul>
<h3><a class="anchor" id="depth_perception_def"></a>
Depth perception</h3>
<p>For depth perception various kinds of sensors exist. Laser scanners emit laser beams that are reflected when the beams hit the surface. The traveling time of the light is used to deduce the distance. Time-of-Flight cameras follow the same principle, but some devices measure the phase shift of a modulated frequency rather than the traveled time. Stereo camera systems consists of two cameras that are mounted on a fixed baseline. As the baseline is known, distances to corresponding points can be calculated via triangulation. Sensor data is often encoded into depth or range images. Although the depth perception is a crucial step for 3D perception, it is assumed in this work that depth images are already given. Algorithms in this domain are typically hardware dependent. This library will provide functionality to turn a depth image into a point cloud representation.</p>
<p>Further information on the implemented algorithms can be found in the depth_perception section.</p>
<h3><a class="anchor" id="filtering_def"></a>
Filtering</h3>
<p>A filter is an algorithm that is able to process a data stream, in this case point cloud data. Three major filtering techniques are often applied to point clouds: noise reduction, size reduction or ROI extraction.</p>
<p>Noise reduction filters try to remedy shortcomings of the sensors measurements. Size reduction filters sub-sample the input data to get an approximated but smaller amount of data. The less input data an algorithms has, the faster the processing is. Filters for ROI extraction follow the same spirit but they reduce the data by focusing on a particular region rather than sub-sampling the complete input data. However how such ROI is derived is out scope of filtering algorithms. The filtering stage can be regarded as optional, but it is a valuable contribution to create more robust or faster results.</p>
<p>Further information on the implemented algorithms can be found in the filtering section.</p>
<h3><a class="anchor" id="feature_extraction_def"></a>
Feature extraction</h3>
<p>Feature extraction methods typically try to detect distinctive points or regions in the input image or point cloud data. Different descriptors exist to describe these regions on a local scale for points and regions or on global scale that takes bigger portions or the complete scene into account.</p>
<p>Normal estimation methods are needed to compute a normal vector for each point in a point cloud. The normal represents the plane normal vector of an underlying patch of the surface. Many algorithms requires point clouds with normals to further process the data.</p>
<p>Further information on the implemented algorithms can be found in the featureExtraction section.</p>
<h3><a class="anchor" id="registration_def"></a>
Registration</h3>
<p>Registration, also sometimes referred as <em>matching</em>, is the process of merging captures from different viewpoints into one global, consistent coordinate frame. This is a robotic problem, because mobile robots move in their environment and thus are able to perceive the environment from different perspectives. Some tasks require to integrate all perceived scene captures into one consistent model to reason about it (for example to plan a path). The most prominent algorithm to solve the registration problem for point clouds is the Iterative Closest Point (ICP) method.</p>
<p>Further information on the implemented algorithms can be found in the registration section.</p>
<h3><a class="anchor" id="segmentation_def"></a>
Segmentation</h3>
<p>Segmentation means a spatial partition of point clouds into subsets that belong to different objects. 3D models of special shapes, like planes, cylinders or speres are often fitted into these regions to model the perceived objects. <br/>
 With respect to a mobile manipulation application that needs a triangle set representation of an environment this stage can be regarded as optional. However, the segmentation of data might be helpful to recognize objects that can be grasped, for example.</p>
<p>Further information on the implemented algorithms can be found in the segmentation section.</p>
<h3><a class="anchor" id="classification_def"></a>
Classification</h3>
<p>A classification algorithm tries to associate the data with categories or objects stored in prior knowledge database. To find such correspondences, methods like for instance Nearest Neighbor Search, Support Vector Machines or Neural Networks can be used.</p>
<p>Further information on the implemented algorithms can be found in the nearestNeighbor section.</p>
<h3><a class="anchor" id="mesh_generation_def"></a>
Mesh generation</h3>
<p>The goal of the mesh generation step is to transform a 3D point cloud into a triangle mesh. Similar terms are <em>meshing, shape recovery, surface recovery, surface reconstruction, model retrieval, inverse CAD or geometric modeling</em> (in computer vision). Most of these terms are used in a broader context that already includes some filtering or registration steps. The notion mesh generation is used here in a more limited way restricted to the part of model transformation from point cloud to triangle mesh.</p>
<p>Further information on the implemented algorithms can be found in the mesh_generation section.</p>
<h3><a class="anchor" id="visualization_def"></a>
Visualization</h3>
<p>Visualization, or rendering, is the process of displaying the 3D models. This involves a transformation from the models into a 2D image, which can be displayed on a monitor. This task is often performed by specialized hardware: graphic adapters. The graphic adapters offer a software interface to render the models that consist of primitive elements like points, lines or polygons. One standardized interface is OpenGL, which allows operating system independent access the graphic adapters. <br/>
 Robotic applications do not necessarily need to visualize the generated models, but visualization can serve as a development or debug tool to visually inspect intermediate results or the output of certain algorithms.</p>
<p>Further information on the implemented algorithms can be found in the visualization section. </p>
</div></div>
<hr class="footer"/><address class="footer"><small>Generated on Wed Oct 24 2012 14:10:25 for BRICS_RN_Robust_Navigation_Library(BRICS_RN) by&#160;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.3 </small></address>
</body>
</html>
